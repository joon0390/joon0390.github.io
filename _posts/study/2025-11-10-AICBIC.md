---
layout: single
title: "AIC & BIC"
date: 2025-11-10
permalink: /aicbic/
categories:
  - Statistics
tags:
  - Akaike Information Criterion
  - Bayesian Information Criterion
  - Information Criterion
toc: true
toc_sticky: true
comments: true
---

회귀분석에 대한 기본적인 내용은 [Linear Regression](/linear-regression/) 포스팅을 참고해주세요

## Multiple Linear Regression

2개 이상의 변수를 설명변수로 사용하는 경우 다음과 같은 회귀 모델을 고려합니다. 

$$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p + \epsilon $$

- 이를 통해 여러 변수의 효과를 파악하고 변수 간의 Partial Effect를 추정합니다.

하지만 변수의 개수가 많아짐에 따라 문제가 발생할 수 있습니다.

## Model Assumption
AIC/BIC에 앞서 회귀모델이 왜 모델의 "품질"을 점검해야 하는 지부터 알아야 합니다.

1. **선형성**
    - $x$와 $y$는 선형 관계에 있어야 한다.

2. **독립성**
    - 모델의 Residual은 서로 독립이어야 한다.

3. **등분산성**
    - 오차의 분산은 일정해야 한다. 

4. **정규성**
    - 오차는 정규분포에 가까워야 한다.

5. **다중공선성 없음**
    - 설명변수 간의 지나치게 높은 상관관계는 문제를 일으킨다.

$\rightarrow$ 이 가정들이 만족되지 않는 경우에는 예측력이 떨어지며 추론에 왜곡이 생길 수 있습니다. 

## Why Model Selection
Multiple Linear Regression에서는 변수를 많이 넣을수록 학습 데이터에 대한 적합도는 좋아집니다.

극단적인 예시로 $R^2$는 더미 변수를 추가하여도 항상 증가하고 SS는 항상 감소합니다.
그래서 Full Model이 더 좋은 것이라고 오해할 수 있습니다.

하지만 이런 경우에는 과적합(overfitting)이 발생하며 해석 가능성이 저하되고 불필요한 변수를 포함하게 될 수 있습니다. 

그래서 모델을 비교하고 적절하게 선택할 기준이 필요해집니다.

여기서 오늘의 주제인 AIC, BIC 같은 모델 평가 지표들의 개념이 나오게 됩니다.


## AIC, BIC
- **AIC : Akaike Information Criterion**
- **BIC : Bayesian Information Criterion**

두 기준들은 다음을 동시에 고려합니다.
1. 모델의 적합도(Likelihood)
2. 변수 개수 $k$에 대한 패널티

즉, 너무 복잡하지 않으면서도 잘 맞는 모델을 선택하기 위한 Information Criterion입니다.

### AIC
AIC는 1974년 Akaike가 정보이론에 기반하여 제안한 Criterion이며, 특히 예측 성능을 중요하게 여기는 방향으로 설계되어 있다.

#### Formula
$$\text{AIC} = -2\log(L) + 2k$$
- $L$ : Likelihood(모델의 적합도)
- $k$ : 모델의 파라미터 개수


#### Interpretation
- $-2\log(L)$은 모델이 데이터를 잘 설명할수록 작아집니다.
- 하지만 변수를 많이 넣으면 Likelihood는 항상 증가하기 때문에 복잡한 모델이 무조건 낮아지는 문제가 발생합니다.

그래서 $2k$ 패널티 term을 추가하여 복잡성을 조절합니다. 


#### 왜 $-2 \log(L)$인가?

Likelihood Ratio Test(LRT)에서는 다음 통계량을 사용합니다.

$$
-2 \left\{ \log L_{\text{reduced}} - \log L_{\text{full}} \right\}
$$

이 값이 [Wilks' Theorem](https://en.wikipedia.org/wiki/Wilks%27_theorem)에 의해 근사적으로 $\chi^2$ 분포를 따르기 때문에 매우 다루기 쉽습니다.

따라서 AIC에서도 **일관성 및 비교 편의성**을 위해 $-2\log(L)$ 형태를 사용합니다.

- 모델의 deviance  
- 가능도비 검정(LRT)  
- $\chi^2$ 기반 해석  
- F-test 구조  

와 스케일을 맞추기 위한 선택입니다.

즉, **이론적으로 자연스럽고 기존 통계 검정 도구와 호환되는 형태이기 때문에**  
AIC를 $-2\log(L)$ 형태로 정의하는 것입니다.


### BIC
BIC는 1978년 Schwarz가 Bayesian 관점에서 제안한 정보 기준입니다. IC와 비슷하지만 패널티를 훨씬 더 강하게 주기 때문에 “단순한 모델”을 선호하게 됩니다.

#### Formula
$$
\text{BIC} = -2\log(L) + k\log(n)
$$

- $n$ : sample size
- $k$ : 파라미터 개수
- $\log(n)$이 penalty 역할




#### Interpretation
- 적합도(데이터 설명력) $\rightarrow$ $-2\log(L)$
- 복잡도 패널티 $\rightarrow$ $k\log(n)$

따라서 BIC는

- 불필요한 변수가 있으면 매우 강하게 패널티를 부여합니다. 
- 따라서 중요한 변수만 남기고 싶은 간결한 모델을 찾는 데 유리합니다.



## Code

아래는 Boston 데이터를 이용해 여러 회귀모형을 만들고 각 모델의 AIC와 BIC를 계산하는 코드와 결과입니다.

{% include code-header.html %}
```{R}
library(MASS)

df <- Boston

# 여러 회귀모형 만들기
fit1 <- lm(medv ~ lstat, data=df)
fit2 <- lm(medv ~ lstat + rm, data=df)
fit3 <- lm(medv ~ lstat + rm + ptratio, data=df)
fit4 <- lm(medv ~ lstat + rm + ptratio + nox, data=df)
fit_full <- lm(medv ~ ., data=df)

# AIC, BIC 추출
aic_values <- c(
  Model1 = AIC(fit1),
  Model2 = AIC(fit2),
  Model3 = AIC(fit3),
  Model4 = AIC(fit4),
  Full   = AIC(fit_full)
)

bic_values <- c(
  Model1 = BIC(fit1),
  Model2 = BIC(fit2),
  Model3 = BIC(fit3),
  Model4 = BIC(fit4),
  Full   = BIC(fit_full)
)

aic_values
bic_values

```
![AIC&BIC](/assets/img/aicbic/image.png)

Boston 데이터에서는

- **Full Model이 AIC/BIC 모두 최적**  
- 이는 13개의 변수들이 medv와 모두 어느 정도 관련이 있어 적합도 개선이 penalty보다 훨씬 크기 때문으로 보입니다.

하지만 해석 가능성을 고려하면 `lstat`, `rm`, `ptratio`만 포함한 **Model3**는 단순하면서도 성능이 높은 “해석 중심 모델”로 충분히 의미가 있다고 볼 수 있습니다.

## Summary

- AIC와 BIC는 모두 "모델의 적절한 복잡도"를 찾기 위한 정보 기준입니다. 
- 둘 다 적합도(−2logL)에서 시작하지만 패널티가 다릅니다. 
- AIC는 예측력 중심 → 패널티 작음(2k)
- BIC는 단순한 모델 중심 → 패널티 큼(k log n)
- 그래서 두 기준은 서로 다른 모델을 선택할 수 있습니다.
- 목적이 "예측"이면 AIC, "해석·단순성"이면 BIC가 적합하다고 할 수 있습니다.


